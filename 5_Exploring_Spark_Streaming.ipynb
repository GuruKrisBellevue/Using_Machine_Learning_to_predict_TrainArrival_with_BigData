{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e4a388-17c0-4a25-ad42-274cf784aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Spark session object\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7042a5f8-7a72-45fc-ab49-d6122bfe0b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/26 01:16:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Creating a spark session object\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName('Demo'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2c76f6-f8fc-4cc9-a6bf-58065b6fe67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the number of shuffle partition as 2 by overriding the default\n",
    "spark.conf.set('spark.sql.shuffle.partitions', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce88778-9ced-4eca-ab28-822abfa3874b",
   "metadata": {},
   "source": [
    "### Spark Streaming reading messages from port 9100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7af62d3-638a-4a92-a92a-46773c426fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: 0: Can't open tail_api.sh\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# This command is run from the console where the content from the file cta_api_dump.csv is streamed to a web server on the port 9100\n",
    "!sh tail_api.sh|nc -lk `hostname -f` 9100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd8cabf-1a75-4be8-b91a-dee72b5934ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigdata-project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries such as socket\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946a1890-d103-4e65-b15d-6725a45646f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/26 01:17:50 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "# Creating a read stream by reading the messages from port 9101\n",
    "api_messages = spark. \\\n",
    "    readStream. \\\n",
    "    format(\"socket\"). \\\n",
    "    option(\"host\", hostname). \\\n",
    "    option(\"port\", 9100). \\\n",
    "    load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f6e91e-8ba2-4c96-bd3a-2c17cc9afa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_messages.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc07b46-d0cd-4c83-94d9-8981bce5c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_messages.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13548b8c-931f-4d27-ad1e-47144981fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/26 01:17:59 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-82610cac-94bb-4e1f-887b-f3ee3e278837. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/02/26 01:17:59 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f19c072e790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                  |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|red,811,30173,Howard,40190,Sox-35th,2024-02-25T19:13:10,2024-02-25T19:15:10,0,41.81036,-87.63101                                       |\n",
      "|red,813,30089,95th/Dan Ryan,41220,Fullerton,2024-02-25T19:13:46,2024-02-25T19:14:46,0,41.92916,-87.65298                               |\n",
      "|red,815,30173,Howard,40540,Wilson,2024-02-25T19:13:53,2024-02-25T19:15:53,0,41.96427,-87.65759                                         |\n",
      "|red,907,30089,95th/Dan Ryan,41660,Lake,2024-02-25T19:13:22,2024-02-25T19:14:22,0,41.88709,-87.62789                                    |\n",
      "|red,912,30173,Howard,41420,Addison,2024-02-25T19:13:38,2024-02-25T19:15:38,0,41.93975,-87.65338                                        |\n",
      "|pink,308,30114,54th/Cermak,40850,Harold Washington Library-State/Van Buren,2024-02-25T19:13:48,2024-02-25T19:14:48,0,41.87652,-87.62601|\n",
      "|pink,312,30114,Loop,40740,Western,2024-02-25T19:13:41,2024-02-25T19:14:41,0,41.85428,-87.69478                                         |\n",
      "|g,008,30004,Harlem/Lake,41700,Washington/Wabash,2024-02-25T19:14:06,2024-02-25T19:15:06,0,41.8795,-87.6261                             |\n",
      "|g,013,30004,Harlem/Lake,40610,Ridgeland,2024-02-25T19:14:12,2024-02-25T19:15:12,0,41.88723,-87.77906                                   |\n",
      "|g,609,30004,Harlem/Lake,40940,Halsted,2024-02-25T19:13:59,2024-02-25T19:14:59,0,41.77915,-87.65158                                     |\n",
      "|g,613,30057,Ashland/63rd,41400,Roosevelt,2024-02-25T19:14:05,2024-02-25T19:15:05,0,41.87223,-87.62676                                  |\n",
      "|g,615,30139,Cottage Grove,40260,State/Lake,2024-02-25T19:14:02,2024-02-25T19:15:02,0,41.88574,-87.63089                                |\n",
      "|org,710,30182,Midway,40380,Clark/Lake,2024-02-25T19:14:17,2024-02-25T19:15:17,0,41.88504,-87.6339                                      |\n",
      "|org,713,30182,Midway,41130,Halsted,2024-02-25T19:14:17,2024-02-25T19:17:17,0,41.85932,-87.62644                                        |\n",
      "|org,715,30182,Loop,40960,Pulaski,2024-02-25T19:14:03,2024-02-25T19:15:03,0,41.79332,-87.73801                                          |\n",
      "|org,710,30182,Midway,40380,Clark/Lake,2024-02-25T19:14:32,2024-02-25T19:15:32,0,41.88573,-87.63274                                     |\n",
      "|org,713,30182,Midway,41130,Halsted,2024-02-25T19:14:31,2024-02-25T19:16:31,0,41.85864,-87.62643                                        |\n",
      "|org,715,30182,Loop,40960,Pulaski,2024-02-25T19:14:23,2024-02-25T19:15:23,0,41.79497,-87.73636                                          |\n",
      "|org,710,30182,Midway,40380,Clark/Lake,2024-02-25T19:14:32,2024-02-25T19:15:32,0,41.88573,-87.63274                                     |\n",
      "|org,713,30182,Midway,41130,Halsted,2024-02-25T19:14:31,2024-02-25T19:16:31,0,41.85864,-87.62643                                        |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Starting a write stream object by reading from api_messages every 10 seconds using append mode\n",
    "api_messages. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"console\"). \\\n",
    "    option('truncate', 'false'). \\\n",
    "    trigger(processingTime='10 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728dcb5c-8f5c-4853-a190-47a68fbb627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from pyspark.sql.functions import split, count, lit\n",
    "# Creating route_count dataframe that groups the data based on the route color and prints the results\n",
    "route_count = api_messages. \\\n",
    "    select(split('value', ',')[0].alias('route_color')). \\\n",
    "    groupBy('route_color'). \\\n",
    "    agg(count(lit(1)).alias('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a32ecc0-6723-4d2e-81e6-00d8d1111728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/26 01:18:15 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-57ab24c9-c167-45a5-9601-b756eeceaabf. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/02/26 01:18:15 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f1998d33850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----------+-----+\n",
      "|route_color|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                        |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|red,810,30173,Howard,41660,Lake,2024-02-25T19:17:52,2024-02-25T19:18:52,0,41.88321,-87.62775                 |\n",
      "|red,812,30089,95th/Dan Ryan,40190,Sox-35th,2024-02-25T19:17:45,2024-02-25T19:18:45,0,41.84691,-87.63114      |\n",
      "|red,814,30089,95th/Dan Ryan,40880,Thorndale,2024-02-25T19:17:55,2024-02-25T19:18:55,0,41.99196,-87.65912     |\n",
      "|red,816,30089,95th/Dan Ryan,41420,Addison,2024-02-25T19:17:43,2024-02-25T19:18:43,0,41.952,-87.65366         |\n",
      "|red,909,30173,Howard,41320,Belmont,2024-02-25T19:16:50,2024-02-25T19:19:50,0,41.92505,-87.65287              |\n",
      "|red,912,30173,Howard,40540,Wilson,2024-02-25T19:17:45,2024-02-25T19:20:45,0,41.95377,-87.65493               |\n",
      "|red,811,30173,Howard,41000,Cermak-Chinatown,2024-02-25T19:17:45,2024-02-25T19:18:45,0,41.84239,-87.63109     |\n",
      "|red,813,30089,95th/Dan Ryan,40630,Clark/Division,2024-02-25T19:17:32,2024-02-25T19:19:32,0,41.91065,-87.64918|\n",
      "|red,815,30173,Howard,40880,Thorndale,2024-02-25T19:17:23,2024-02-25T19:19:23,0,41.97345,-87.65853            |\n",
      "|red,907,30089,95th/Dan Ryan,41490,Harrison,2024-02-25T19:17:33,2024-02-25T19:18:33,0,41.87815,-87.6276       |\n",
      "|red,910,30173,Howard,40240,79th,2024-02-25T19:17:40,2024-02-25T19:18:40,0,41.73737,-87.6248                  |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|blue,110,30171,O'Hare,40250,Kedzie-Homan,2024-02-25T19:17:04,2024-02-25T19:19:04,0,41.87389,-87.72517    |\n",
      "|blue,114,30077,Forest Park,40430,Clinton,2024-02-25T19:17:35,2024-02-25T19:19:35,0,41.87557,-87.63327    |\n",
      "|blue,117,30171,O'Hare,40180,Oak Park,2024-02-25T19:17:30,2024-02-25T19:18:30,0,41.87306,-87.80251        |\n",
      "|blue,213,30171,O'Hare,40820,Rosemont,2024-02-25T19:17:49,2024-02-25T19:18:49,0,41.98363,-87.85659        |\n",
      "|blue,215,30171,O'Hare,41340,LaSalle,2024-02-25T19:17:49,2024-02-25T19:18:49,0,41.8756,-87.63728          |\n",
      "|blue,217,30077,Forest Park,40550,Irving Park,2024-02-25T19:17:34,2024-02-25T19:19:34,0,41.96149,-87.74362|\n",
      "|blue,113,30077,Forest Park,40920,Pulaski,2024-02-25T19:17:51,2024-02-25T19:19:51,0,41.87401,-87.71586    |\n",
      "|blue,115,30077,Forest Park,40820,Rosemont,2024-02-25T19:17:41,2024-02-25T19:20:41,0,41.97714,-87.89023   |\n",
      "|blue,210,30077,Forest Park,40590,Damen,2024-02-25T19:17:40,2024-02-25T19:18:40,0,41.91066,-87.67887      |\n",
      "|blue,214,30171,O'Hare,41020,Logan Square,2024-02-25T19:17:49,2024-02-25T19:18:49,0,41.92666,-87.70448    |\n",
      "|blue,216,30077,Forest Park,40010,Austin,2024-02-25T19:17:48,2024-02-25T19:18:48,0,41.87036,-87.76809     |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|org,708,30182,Midway,40930,Midway,2024-02-25T19:17:56,2024-02-25T19:18:56,0,41.79572,-87.735      |\n",
      "|org,711,30182,Loop,41400,Roosevelt,2024-02-25T19:18:13,2024-02-25T19:21:13,0,41.85699,-87.63327   |\n",
      "|org,714,30182,Midway,40040,Quincy,2024-02-25T19:18:17,2024-02-25T19:19:17,0,41.87697,-87.63365    |\n",
      "|org,710,30182,Midway,40680,Adams/Wabash,2024-02-25T19:18:13,2024-02-25T19:19:13,0,41.8795,-87.6261|\n",
      "|org,713,30182,Midway,41060,Ashland,2024-02-25T19:18:11,2024-02-25T19:19:11,0,41.84305,-87.65759   |\n",
      "|org,715,30182,Loop,40310,Western,2024-02-25T19:18:14,2024-02-25T19:19:14,0,41.80444,-87.69922     |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using \"complete\" mode to print the resul\n",
    "route_count. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"complete\"). \\\n",
    "    format(\"console\"). \\\n",
    "    option('truncate', 'false'). \\\n",
    "    trigger(processingTime='10 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3b425-7a40-4b7b-a932-35ee6542cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using \"update\" mode to print the results to the console\n",
    "route_count. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"update\"). \\\n",
    "    format(\"console\"). \\\n",
    "    option('truncate', 'false'). \\\n",
    "    trigger(processingTime='10 seconds'). \\\n",
    "    start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
